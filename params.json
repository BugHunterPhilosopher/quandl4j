{"name":"Quandl4j","tagline":"A Quandl API wrapper for Java","body":"Quandl4J : A Quandl library for Java\r\n====================================\r\n\r\n**Announcement: There will be a new version of Quandl4J in the next few days to handle the recent deprecation of multisets\r\nfrom the Quandl REST API**\r\n\r\n[Quandl](http://quandl.com) is a source of millions of free data sets covering financial, economic, sociological and country data via an open REST API.  **Quandl4j** is a Java 7+ client-side wrapper for this API provided under the commercially friendly [Apache V2 license](http://www.apache.org/licenses/LICENSE-2.0.html).  It provides a type safe and fluent API in a modern style that takes care of constructing URLs and processing JSON and CSV responses but nonetheless allows access to all the functionality of the underlying REST API.\r\n\r\nQuandl4J uses [Travis CI](http://travis-ci.org/jimmoores/quandl4j) to perform continuous builds.  The current status is ![Master Branch Build Status](https://travis-ci.org/jimmoores/quandl4j.svg?branch=master)\r\n\r\n# Table of Contents\r\n - [Quick start](#quick-start)\r\n - [Design Principles](#design-principles)\r\n - [Tutorial](#tutorial)\r\n - [Documentation](#documentation)\r\n - [Roadmap](#roadmap)\r\n - [Contributing](#contributing)\r\n - [Community](#community)\r\n - [Versioning](#versioning)\r\n - [Bugs and feature requests](#bugs-and-feature-requests)\r\n - [Creator](#creator)\r\n - [Copyright and license](#copyright-and-license)\r\n\r\n### Quick Start\r\nThe minimum pre-requisites are:\r\n - OpenJDK 7, Oracle JDK 7 & 8 are tested.\r\n - Maven 3.\r\n\r\nThree options are available:\r\n - [Download the latest release](https://github.com/jimmoores/quandl4j/archive/rel/v0.8.1.zip)\r\n - Clone the repository: `git clone https://github.com/jimmoores/quandl4j.git`\r\n   - Run `mvn install` to build the libray, test, javadoc and source jars and install to your local Maven repository.\r\n   - Run `mvn javadoc:javadoc` to build the documentation.\r\n - Add the following fragment to your Maven POM file\r\n```xml\r\n<dependency>\r\n  <groupId>com.jimmoores</groupId>\r\n  <artifactId>quandl</artifactId>\r\n  <version>0.8.1</version>\r\n</dependency>\r\n```\r\n### Design Principles\r\nThe core design principles are:\r\n - Allow full access to the functionality of the underlying API.\r\n - Allow efficient network requests by using the more compact CSV encoding where\r\n   possible.\r\n - Use modern Java design principles like immutable objects, builders and \r\n   factories and JSR-310 style date/times (using the [ThreeTen backport](http://threeten.org) so Java 7 is supported)\r\n - Thorough unit and integration test support, including a framework that can\r\n   be reused by user applications without hitting the Quandl backend.\r\n - Publish maven artifacts on [Maven Central](http://search.maven.org/).\r\n - Provide concrete examples.\r\n - Provide comprehensive documentation and JavaDocs.\r\n\r\n## Tutorial\r\n### A First Taste of the API\r\nThe following gets the complete data history (with Date, Open, High, Low, Volume, Ex-Dividend, Split Ratio, And Adjusted Open, High, Low Close and Volume columns) of AAPL (Apple Inc).  The symbol `WIKI/AAPL` is what is known as the **Quandl code** and is made up of a data source (in this case `WIKI`) and a data source specific code (in this case the exchange code for Apple Inc, which is `AAPL`).\r\n```java\r\n// Example1.java\r\nQuandlSession session = QuandlSession.create();\r\nTabularResult tabularResult = session.getDataSet(\r\n  DataSetRequest.Builder.of(\"WIKI/AAPL\").build());\r\nSystem.out.println(tabularResult.toPrettyPrintedString());\r\n```\r\nwhich produces\r\n```\r\n+------------+--------+----------+----------+----------+------------+-------------+-------------+-----------------+-----------------+-----------------+-----------------+-------------+\r\n| Date       | Open   | High     | Low      | Close    | Volume     | Ex-Dividend | Split Ratio | Adj. Open       | Adj. High       | Adj. Low        | Adj. Close      | Adj. Volume |\r\n+------------+--------+----------+----------+----------+------------+-------------+-------------+-----------------+-----------------+-----------------+-----------------+-------------+\r\n| 2014-06-03 | 628.47 | 638.74   | 628.25   | 637.54   | 10419625.0 | 0.0         | 1.0         | 628.47          | 638.74          | 628.25          | 637.54          | 10419625.0  |\r\n| 2014-06-02 | 634.0  | 634.83   | 622.5    | 628.65   | 13149746.0 | 0.0         | 1.0         | 634.0           | 634.83          | 622.5           | 628.65          | 13149746.0  |\r\n| 2014-05-30 | 637.98 | 644.17   | 628.9    | 633.0    | 20073091.0 | 0.0         | 1.0         | 637.98          | 644.17          | 628.9           | 633.0           | 20073091.0  |\r\n| 2014-05-29 | 628.0  | 636.87   | 627.77   | 635.38   | 13352669.0 | 0.0         | 1.0         | 628.0           | 636.87          | 627.77          | 635.38          | 13352669.0  |\r\n... snip ...\r\n| 1980-12-17 | 25.88  | 26.0     | 25.88    | 25.88    | 385900.0    | 0.0        | 1.0         | 3.0057815128016 | 3.0197186759213 | 3.0057815128016 | 3.0057815128016 | 3087200.0   |\r\n| 1980-12-16 | 25.38  | 25.38    | 25.25    | 25.25    | 472000.0    | 0.0        | 1.0         | 2.9477099998031 | 2.9477099998031 | 2.9326114064235 | 2.9326114064235 | 3776000.0   |\r\n| 1980-12-15 | 27.38  | 27.38    | 27.25    | 27.25    | 785200.0    | 0.0        | 1.0         | 3.1799960517971 | 3.1799960517971 | 3.1648974584175 | 3.1648974584175 | 6281600.0   |\r\n| 1980-12-12 | 28.75  | 28.88    | 28.75    | 28.75    | 2093900.0   | 0.0        | 1.0         | 3.3391119974129 | 3.3542105907925 | 3.3391119974129 | 3.3391119974129 | 16751200.0  |\r\n+------------+--------+----------+----------+----------+-------------+------------+-------------+-----------------+-----------------+-----------------+-----------------+-------------+\r\n```\r\n### Refining the query\r\nIt's also possible to specify many refining options on your query.  In this next example we\r\nrequest AAPL again, but this time sampled Quarterly, returning only the close column (CLOSE_COLUMN here is actually the integer constant 4), and performing a normalization pre-process step on the server side before returning the results.\r\n```java\r\n// Example2.java\r\nQuandlSession session = QuandlSession.create();\r\nTabularResult tabularResult = session.getDataSet(\r\n  DataSetRequest.Builder\r\n    .of(\"WIKI/AAPL\")\r\n    .withFrequency(Frequency.QUARTERLY)\r\n    .withColumn(CLOSE_COLUMN)\r\n    .withTransform(Transform.NORMALIZE)\r\n    .build());\r\nSystem.out.println(tabularResult.toPrettyPrintedString());\r\n```\r\nwhich will return something like\r\n```\r\n+------------+-----------------+\r\n| Date       | Close           |\r\n+------------+-----------------+\r\n| 2014-06-30 | 1868.5228604924 |\r\n| 2014-03-31 | 1573.0949589683 |\r\n| 2013-12-31 | 1644.2555685815 |\r\n| 2013-09-30 | 1397.2743259086 |\r\n| 2013-06-30 | 1162.162954279  |\r\n... snip ...\r\n| 1982-03-31 | 49.47245017585  |\r\n| 1981-12-31 | 64.830011723329 |\r\n| 1981-09-30 | 44.695193434936 |\r\n| 1981-06-30 | 76.20164126612  |\r\n| 1981-03-31 | 71.805392731536 |\r\n| 1980-12-31 | 100.0           |\r\n+------------+-----------------+\r\n```\r\nnote that the whole series is normalized against the first value.\r\n### Retrieving data for multiple Quandl codes at the same time\r\nTo retrieve data for multiple codes, we need a different request structure.  In particular we need to say which Quandl codes we want data retrieved for, but also which columns are required for each.  This is done using the `QuandlCodeRequest`, which has two factory methods: `singleColumn(String quandlCode, int columnIndex)` and `allColumns(String quandlCode)`.  It's worth noting we're allowed to use the normal form of Quandl codes here, in the REST API, the forward slash gets replaced with a full-stop/period in this context:\r\n```java\r\n// Example3.java\r\nQuandlSession session = QuandlSession.create();\r\nTabularResult tabularResultMulti = session.getDataSets(\r\n    MultiDataSetRequest.Builder\r\n      .of(\r\n        QuandlCodeRequest.singleColumn(\"WIKI/AAPL\", CLOSE_COLUMN), \r\n        QuandlCodeRequest.allColumns(\"DOE/RWTC\")\r\n      )\r\n      .withStartDate(RECENTISH_DATE)\r\n      .withFrequency(Frequency.MONTHLY)\r\n      .build());\r\nSystem.out.println(tabularResultMulti.toPrettyPrintedString()); \r\n```\r\nwhich returns all results in a single `TabularResult`\r\n```\r\n+------------+-------------------+------------------+\r\n| Date       | WIKI.AAPL - Close | DOE.RWTC - Value |\r\n+------------+-------------------+------------------+\r\n| 2014-06-30 | 637.54            |                  |\r\n| 2014-05-31 | 633.0             | 103.37           |\r\n| 2014-04-30 | 590.09            | 100.07           |\r\n| 2014-03-31 | 536.74            | 101.57           |\r\n| 2014-02-28 | 526.24            | 102.88           |\r\n| 2014-01-31 | 500.6             | 97.55            |\r\n| 2013-12-31 | 561.02            | 98.17            |\r\n| 2013-11-30 | 556.07            | 92.55            |\r\n| 2013-10-31 | 522.7             | 96.29            |\r\n| 2013-09-30 | 476.75            | 102.36           |\r\n| 2013-08-31 | 487.22            | 107.98           |\r\n| 2013-07-31 | 452.53            | 105.1            |\r\n| 2013-06-30 | 396.53            | 96.36            |\r\n| 2013-05-31 | 449.73            | 91.93            |\r\n| 2013-04-30 | 442.78            | 93.22            |\r\n| 2013-03-31 | 442.66            | 97.24            |\r\n| 2013-02-28 | 441.4             | 92.03            |\r\n| 2013-01-31 | 455.49            | 97.65            |\r\n+------------+-------------------+------------------+\r\n```\r\nNote that the column labels actually do have a **SPACE-HYPHEN-SPACE** between the Quandl code and the Column name.  A future version of the library should allow these columns to be separated out automatically.\r\n### Structure of a TabularResult\r\nThe type `TabularResult` is made up of a `HeaderDefinition`, which is essentially a list of column names (plus the facility to map from name to column index), plus a list of `Row` objects, each of which is linked to their common `HeaderDefinition`.  This allows individual `Row` objects to address their data using the column name rather than just the index as is the underlying API.  `Row` also contains methods to parse and cast data into various types (String, LocalDate, Double).  Here is an example\r\n```java\r\n// Example3a.java\r\nQuandlSession session = QuandlSession.create();\r\nTabularResult tabularResultMulti = session.getDataSets(\r\n    MultiDataSetRequest.Builder\r\n      .of(\r\n        QuandlCodeRequest.singleColumn(\"WIKI/AAPL\", CLOSE_COLUMN), \r\n        QuandlCodeRequest.allColumns(\"DOE/RWTC\")\r\n      )\r\n      .withStartDate(RECENTISH_DATE)\r\n      .withFrequency(Frequency.MONTHLY)\r\n      .build());\r\nSystem.out.println(\"Header definition: \" + tabularResultMulti.getHeaderDefinition());\r\nIterator<Row> iter = tabularResultMulti.iterator();\r\nwhile (iter.hasNext()) {\r\n  Row row = iter.next();\r\n  LocalDate date = row.getLocalDate(\"Date\");\r\n  Double value = row.getDouble(\"DOE.RWTC - Value\");\r\n  System.out.println(\"Value on date \" + date + \" was \" + value);\r\n} \r\n```\r\nproduces:\r\n```\r\nHeader definition: HeaderDefinition[Date,WIKI.AAPL - Close,DOE.RWTC - Value]\r\nValue on date 2014-06-30 was null\r\nValue on date 2014-05-31 was 103.37\r\nValue on date 2014-04-30 was 100.07\r\nValue on date 2014-03-31 was 101.57\r\nValue on date 2014-02-28 was 102.88\r\nValue on date 2014-01-31 was 97.55\r\nValue on date 2013-12-31 was 98.17\r\nValue on date 2013-11-30 was 92.55\r\nValue on date 2013-10-31 was 96.29\r\nValue on date 2013-09-30 was 102.36\r\nValue on date 2013-08-31 was 107.98\r\nValue on date 2013-07-31 was 105.1\r\nValue on date 2013-06-30 was 96.36\r\nValue on date 2013-05-31 was 91.93\r\nValue on date 2013-04-30 was 93.22\r\nValue on date 2013-03-31 was 97.24\r\nValue on date 2013-02-28 was 92.03\r\nValue on date 2013-01-31 was 97.65\r\n'''\r\n\r\n### Single meta data request\r\nIt's also possible to retrieve meta-data about the data sets available.\r\n```java\r\n// Example4.java\r\nQuandlSession session = QuandlSession.create();\r\nMetaDataResult metaData = session.getMetaData(MetaDataRequest.of(\"WIKI/AAPL\"));\r\nSystem.out.println(metaData.toPrettyPrintedString());\r\n```\r\nwhich prints out the raw JSON of the underlying message\r\n```json\r\n{\r\n  \"code\": \"AAPL\",\r\n  \"column_names\": [\r\n    \"Date\",\r\n    \"Open\",\r\n    \"High\",\r\n    \"Low\",\r\n    \"Close\",\r\n    \"Volume\",\r\n    \"Ex-Dividend\",\r\n    \"Split Ratio\",\r\n    \"Adj. Open\",\r\n    \"Adj. High\",\r\n    \"Adj. Low\",\r\n    \"Adj. Close\",\r\n    \"Adj. Volume\"\r\n  ],\r\n  \"description\": \"\\r\\n<p>End of day open, high, low, close and volume, dividends and splits, and split/dividend adjusted open, high, low close and volume for Apple Inc. (AAPL). Ex-Dividend is non-zero on ex-dividend dates. Split Ratio is 1 on non-split dates. Adjusted prices are calculated per CRSP (<a href=\\\"http://www.crsp.com/products/documentation/crsp-calculations\\\" rel=\\\"nofollow\\\" target=\\\"blank\\\">www.crsp.com/products/documentation/crsp-calculations<\\/a>)<\\/p>\\r\\n\\r\\n<p>This data is in the public domain. You may copy, distribute, disseminate or include the data in other products for commercial and/or noncommercial purposes.<\\/p>\\r\\n\\r\\n<p>This data is part of Quandl's Wiki initiative to get financial data permanently into the public domain. Quandl relies on users like you to flag errors and provide data where data is wrong or missing. Get involved: <a href=\\\"mailto:connect@quandl.com\\\" rel=\\\"nofollow\\\" target=\\\"blank\\\">connect@quandl.com<\\/a>\\r\\n<\\/p>\\r\\n\",\r\n  \"display_url\": \"http://www.quandl.com/WIKI/AAPL\",\r\n  \"errors\": {},\r\n  \"frequency\": \"daily\",\r\n  \"from_date\": \"1980-12-12\",\r\n  \"id\": 9775409,\r\n  \"name\": \"Apple Inc. (AAPL) Prices, Dividends, Splits and Trading Volume\",\r\n  \"private\": false,\r\n  \"source_code\": \"WIKI\",\r\n  \"source_name\": \"Quandl Open Data\",\r\n  \"to_date\": \"2014-06-03\",\r\n  \"type\": null,\r\n  \"updated_at\": \"2014-06-03T20:58:42Z\",\r\n  \"urlize_name\": \"Apple-Inc-AAPL-Prices-Dividends-Splits-and-Trading-Volume\"\r\n}\r\n```\r\nThe raw JSON message is accessible, but the intention is for the user to mostly use the convenience methods available to extract named fields (with type casts) and process the `column_names` array into a `HeaderDefinition`.\r\n### Bulk meta-data\r\nThis uses an undocumented feature of Quandl, which allows you to make requests for JSON to the multisets endpoint.  To this we add the parameter to limit the start date to a date far in the future.  This means we only get the meta-data.  It's limited to only providing enough data to determine the available columns, but that's quite useful in itself.  There are two calls that can process this `MultiMetaDataRequest`.  The first is an overloaded version of `getMetaData`.  Again, it's worth noting we're allowed to use the normal form of Quandl codes here: in the REST API, the forward slash gets replaced with a full-stop/period in this context.\r\n```java\r\n// Example5.java\r\nQuandlSession session = QuandlSession.create();\r\nMetaDataResult metaData = session.getMetaData(MultiMetaDataRequest.of(\"WIKI/AAPL\", \"DOE/RWTC\", \"WIKI/MSFT\"));\r\nSystem.out.println(metaData.toPrettyPrintedString());\r\n```\r\nwhich returns a large JSON document wrapped in a normal MetaDataResult object.\r\n```json\r\n{\r\n  \"column_names\": [\r\n    \"Date\",\r\n    \"WIKI.AAPL - Open\",\r\n    \"WIKI.AAPL - High\",\r\n    \"WIKI.AAPL - Low\",\r\n    \"WIKI.AAPL - Close\",\r\n    \"WIKI.AAPL - Volume\",\r\n    \"WIKI.AAPL - Ex-Dividend\",\r\n    \"WIKI.AAPL - Split Ratio\",\r\n    \"WIKI.AAPL - Adj. Open\",\r\n    \"WIKI.AAPL - Adj. High\",\r\n    \"WIKI.AAPL - Adj. Low\",\r\n    \"WIKI.AAPL - Adj. Close\",\r\n    \"WIKI.AAPL - Adj. Volume\",\r\n    \"DOE.RWTC - Value\",\r\n    \"WIKI.MSFT - Open\",\r\n    \"WIKI.MSFT - High\",\r\n    \"WIKI.MSFT - Low\",\r\n    \"WIKI.MSFT - Close\",\r\n    \"WIKI.MSFT - Volume\",\r\n    \"WIKI.MSFT - Ex-Dividend\",\r\n    \"WIKI.MSFT - Split Ratio\",\r\n    \"WIKI.MSFT - Adj. Open\",\r\n    \"WIKI.MSFT - Adj. High\",\r\n    \"WIKI.MSFT - Adj. Low\",\r\n    \"WIKI.MSFT - Adj. Close\",\r\n    \"WIKI.MSFT - Adj. Volume\"\r\n  ],\r\n  \"columns\": [\r\n    \"Date\",\r\n    \"Open\",\r\n    \"High\",\r\n    \"Low\",\r\n    \"Close\",\r\n    \"Volume\",\r\n    \"Ex-Dividend\",\r\n    \"Split Ratio\",\r\n    \"Adj. Open\",\r\n    \"Adj. High\",\r\n    \"Adj. Low\",\r\n    \"Adj. Close\",\r\n    \"Adj. Volume\",\r\n    \"Value\",\r\n    \"Open\",\r\n    \"High\",\r\n    \"Low\",\r\n    \"Close\",\r\n    \"Volume\",\r\n    \"Ex-Dividend\",\r\n    \"Split Ratio\",\r\n    \"Adj. Open\",\r\n    \"Adj. High\",\r\n    \"Adj. Low\",\r\n    \"Adj. Close\",\r\n    \"Adj. Volume\"\r\n  ],\r\n  \"data\": [],\r\n  \"errors\": {},\r\n  \"frequency\": \"annual\",\r\n  \"from_date\": null,\r\n  \"to_date\": null\r\n}\r\n```\r\nA more generally useful method though, is to use the `getMultipleHeaderDefinition()` method\r\n```java\r\n// Example6.java\r\nQuandlSession session = QuandlSession.create();\r\nMap<String, HeaderDefinition> headers = session.getMultipleHeaderDefinition(MultiMetaDataRequest.of(\"WIKI/AAPL\", \"DOE/RWTC\", \"WIKI/MSFT\"));\r\nSystem.out.println(PrettyPrinter.toPrettyPrintedString(headers));\r\n```\r\nwhich returns the following map (`PrettyPrinter` contains a PrettyPrinter for these maps too):\r\n```\r\nWIKI.AAPL => Date, Open, High, Low, Close, Volume, Ex-Dividend, Split Ratio, Adj. Open, Adj. High, Adj. Low, Adj. Close, Adj. Volume\r\nDOE.RWTC  => Date, Value\r\nWIKI.MSFT => Date, Open, High, Low, Close, Volume, Ex-Dividend, Split Ratio, Adj. Open, Adj. High, Adj. Low, Adj. Close, Adj. Volume\r\n```\r\n### Searching\r\nWe can also make generalised free-text search requests to Quandl.  For this we use the `search(SearchRequest)` method.  This allows us to specify the maximum number of results per page, and also the page we want.  Note that queries with high page numbers are slow, presumably due to the server-side database having to project the entire result set of several million documents just to get the single page you want.  Try not to add to server load by making these requests excessively.\r\n```java\r\n// Example7.java\r\nQuandlSession session = QuandlSession.create();\r\nSearchResult searchResult = session.search(SearchRequest.Builder.of(\"Apple\").withMaxPerPage(2).build());\r\nSystem.out.println(searchResult.toPrettyPrintedString());\r\n````\r\nresults in\r\n```json\r\n{\r\n  \"current_page\": 1,\r\n  \"docs\": [\r\n    {\r\n      \"code\": \"NASDAQ_AAPL\",\r\n      \"column_names\": [\r\n        \"Date\",\r\n        \"Open\",\r\n        \"High\",\r\n        \"Low\",\r\n        \"Close\",\r\n        \"Volume\"\r\n      ],\r\n      \"description\": \"Apple Inc. (Apple) designs, manufactures and markets mobile communication and media devices, personal computers, and portable digital music players, and a variety of related software, services, peripherals, networking solutions, and third-party digital content and applications. The Company's products and services include iPhone, iPad, Mac, iPod, Apple TV, a portfolio of consumer and professional software applications, the iOS and OS X operating systems, iCloud, and a variety of accessory, service and support offerings. The Company also delivers digital content and applications through the iTunes Store, App StoreSM, iBookstoreSM, and Mac App Store. The Company distributes its products worldwide through its retail stores, online stores, and direct sales force, as well as through third-party cellular network carriers, wholesalers, retailers, and value-added resellers. In February 2012, the Company acquired app-search engine Chomp.\",\r\n      \"display_url\": \"http://www.google.com/finance/historical?q=NASDAQ%3AAAPL&startdate=Jan+1%2C+1990&output=csv\",\r\n      \"frequency\": \"daily\",\r\n      \"from_date\": \"1981-03-11\",\r\n      \"id\": 2318865,\r\n      \"name\": \"Apple Inc. (AAPL)\",\r\n      \"private\": false,\r\n      \"source_code\": \"GOOG\",\r\n      \"source_name\": \"Google Finance\",\r\n      \"to_date\": \"2014-06-03\",\r\n      \"type\": null,\r\n      \"updated_at\": \"2014-06-04T02:27:30Z\",\r\n      \"urlize_name\": \"Apple-Inc-AAPL\"\r\n    },\r\n    {\r\n      \"code\": \"AAPL_CASH\",\r\n      \"column_names\": [\r\n        \"Date\",\r\n        \"Cash\"\r\n      ],\r\n      \"description\": \"Cash and Marketable Securities reported in the balance sheet. Units: millions of dollars. Corporate Finance data is collected and calculated by Prof. Aswath\\nDamodaran, Professor of Finance at the Stern School of Business, New\\nYork University.  The raw data is available here:\\nhttp://pages.stern.nyu.edu/~adamodar/New_Home_Page/data.html\",\r\n      \"display_url\": \"http://pages.stern.nyu.edu/~adamodar/New_Home_Page/data.html\",\r\n      \"frequency\": \"annual\",\r\n      \"from_date\": \"2000-09-27\",\r\n      \"id\": 3861439,\r\n      \"name\": \"Apple Inc. ( AAPL ) - Cash\",\r\n      \"private\": false,\r\n      \"source_code\": \"DMDRN\",\r\n      \"source_name\": \"Damodaran Financial Data\",\r\n      \"to_date\": \"2013-09-27\",\r\n      \"type\": null,\r\n      \"updated_at\": \"2014-05-15T18:07:39Z\",\r\n      \"urlize_name\": \"Apple-Inc-AAPL-Cash\"\r\n    }\r\n  ],\r\n  \"per_page\": 2,\r\n  \"sources\": [\r\n    {\r\n      \"code\": \"DMDRN\",\r\n      \"datasets_count\": 0,\r\n      \"description\": \"\",\r\n      \"host\": \"pages.stern.nyu.edu/~adamodar/\",\r\n      \"id\": 6946,\r\n      \"name\": \"Damodaran Financial Data\"\r\n    },\r\n    {\r\n      \"code\": \"GOOG\",\r\n      \"datasets_count\": 43144,\r\n      \"description\": \"This data is NOT sourced directly from Google.  It is however verified against their numbers.\\r\\n\\r\\nwww.quandl.com/WIKI is a better source.\",\r\n      \"host\": \"www.google.com\",\r\n      \"id\": 393,\r\n      \"name\": \"Google Finance\"\r\n    }\r\n  ],\r\n  \"total_count\": 4563\r\n}\r\n```\r\nMore usefully though, there are variously helper methods on SearchResult to allow you to get the document count, number of documents per page and to extract the individual matches as separate MetaDataResult objects.  For example\r\n```java\r\n// Example8.java\r\nQuandlSession session = QuandlSession.create();\r\nSearchResult searchResult = session.search(SearchRequest.Builder.of(\"Apple\").withMaxPerPage(2).build());\r\nSystem.out.println(\"Current page:\" + searchResult.getCurrentPage());\r\nSystem.out.println(\"Documents per page:\" + searchResult.getDocumentsPerPage());\r\nSystem.out.println(\"Total matching documents:\" + searchResult.getTotalDocuments());\r\nfor (MetaDataResult document : searchResult.getMetaDataResultList()) {\r\n  System.out.println(\"Quandl code \" + document.getQuandlCode() + \" matched\");\r\n  System.out.println(\"Available columns are: \" + document.getHeaderDefinition());\r\n}\r\n```\r\nproduces\r\n```\r\nCurrent page:1\r\nDocuments per page:2\r\nTotal matching documents:4563\r\nQuandl code GOOG/NASDAQ_AAPL matched\r\nAvailable columns are: HeaderDefinition[Date,Open,High,Low,Close,Volume]\r\nQuandl code DMDRN/AAPL_CASH matched\r\nAvailable columns are: HeaderDefinition[Date,Cash]\r\n```\r\n### Documentation\r\nAn addition to the tutorial, there is extra documentation at the package and class level within the [JavaDocs, which are hosted in GitHub Pages](http://jimmoores.github.io/quandl4j/apidocs).\r\n\r\n### Roadmap\r\nSome future plans for incorporation include:\r\n - Caching layer to speed up queries and minimize quandl traffic.\r\n - Ability to subselect columns/date ranges out from `TabularResult`.\r\n - Example Swing UI.\r\n - Locally stored data with ability to update (i.e. persistent cache).\r\n - Ability to specify column names in requests that will use cached metadata where possible or fall back to \r\n   performing a metadata request prior to a data request.\r\n\r\n### Contrubutions\r\nContributions are welcome!  Please read through the [contributing guidelines](http://github.com/jimmoores/quandl4j/blob/master/CONTRIBUTING.md).  This gives guidelines on opening issues, coding standards and testing requirements.\r\n\r\n### Community\r\nFollow development here via\r\n - Twitter\r\n - Email\r\n\r\n### Versioning\r\nReleases will be numbered with the format `<major>.<minor>.<patch-level>`.  When to bump a version number will be dictated by:\r\n - Breaking backwards API compatibility will mean a bump in the major version number.\r\n - New features that retain backwards compatibility will require a minor version number bump.\r\n - Pure bug fixes will bump the patch-level.\r\n \r\n### Creator\r\n**Jim Moores**\r\n - <http://twitter.com/jim_moores>\r\n - <http://github.com/jimmoores>\r\n - <https://www.linkedin.com/pub/jim-moores/0/442/841>\r\n \r\n### Copyright and license\r\n\r\nCode and documentation Copyright (C) 2014 Jim Moores.  Code and documentation released under the [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0.html)\r\n \r\n\r\n","google":"UA-51676168-1","note":"Don't delete this file! It's used internally to help with page regeneration."}